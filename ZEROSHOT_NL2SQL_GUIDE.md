# üöÄ Zero-shot NL2SQL System for ViText2SQL

A comprehensive zero-shot Natural Language to SQL generation system using LangChain, specifically designed for Vietnamese ViText2SQL dataset.

## üåü Features

- **Multiple LLM Support**: OpenAI GPT-4, GPT-4o, Anthropic Claude models
- **Comprehensive Logging**: Full request/response tracking with structured JSON logs
- **Detailed Evaluation**: Exact match, execution accuracy, component analysis
- **Vietnamese Language Support**: Optimized for Vietnamese NL2SQL tasks
- **Schema-aware Generation**: Utilizes complete database schema information
- **Error Analysis**: Detailed error categorization and debugging information

## üìã Prerequisites

1. **Python Environment**: Python 3.8+ with virtual environment
2. **API Keys**: OpenAI and/or Anthropic API keys
3. **Dataset**: ViText2SQL dataset with SQLite databases

## üîß Setup

### 1. Environment Setup
```bash
# Virtual environment is already created
source venv/bin/activate

# Packages are already installed:
# langchain, langchain-openai, langchain-anthropic, python-dotenv, sqlparse
```

### 2. API Key Configuration
Edit the `.env` file with your API keys:
```bash
# OpenAI API Key (for GPT models)
OPENAI_API_KEY=sk-your-openai-key-here

# Anthropic API Key (for Claude models)  
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# Optional: LangChain tracing
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your-langchain-key-here
```

### 3. Model Configuration
Available models:
- **OpenAI**: `gpt-4o`, `gpt-4o-mini`, `gpt-4-turbo`
- **Anthropic**: `claude-3-opus-20240229`, `claude-3-sonnet-20240229`, `claude-3-haiku-20240307`

## üöÄ Usage

### Quick Start
```bash
# Test with 3 samples using GPT-4o-mini
python zeroshot_nl2sql.py

# Run evaluation with specific model
python config_nl2sql.py --model gpt-4o-mini --split dev --samples 10
```

### Advanced Usage

#### 1. Single Model Evaluation
```bash
# Evaluate 20 samples from dev set with GPT-4
python config_nl2sql.py --model gpt-4o --split dev --samples 20

# Evaluate 50 samples from test set with Claude
python config_nl2sql.py --model claude-3-haiku-20240307 --split test --samples 50

# Full evaluation on train set (all samples)
python config_nl2sql.py --model gpt-4o-mini --split train --samples -1
```

#### 2. Different Tokenization Levels
```bash
# Syllable-level tokenization (default)
python config_nl2sql.py --level syllable --samples 20

# Word-level tokenization
python config_nl2sql.py --level word --samples 20
```

#### 3. Custom Dataset Path
```bash
python config_nl2sql.py --dataset-path /path/to/your/ViText2SQL --samples 10
```

## üìä Output and Logging

### 1. Console Output
The system provides real-time feedback:
```
üîÑ Running evaluation on dev split with 10 samples
üìä Model: gpt-4o-mini
üìÅ Dataset: dataset/ViText2SQL/syllable-level
============================================================
‚úÖ Loaded 10 samples from dev split

üìù Processing 1/10: architecture
‚úÖ Exact match!

üìù Processing 2/10: academic  
üü° Execution accurate but different syntax
```

### 2. Structured Logs
All operations are logged to `logs/nl2sql_logs.json`:
```json
{
  "request_id": "req_1234567890",
  "timestamp": "2024-01-15T10:30:45",
  "type": "REQUEST",
  "question": "C√≥ t·∫•t c·∫£ bao nhi√™u ki·∫øn tr√∫c s∆∞ n·ªØ?",
  "db_id": "architecture"
}
```

### 3. Results Files
Evaluation results are saved to `results/` directory:
```json
{
  "config": {
    "model": "gpt-4o-mini",
    "split": "dev", 
    "level": "syllable",
    "num_samples": 10
  },
  "summary": {
    "exact_match_accuracy": 85.0,
    "execution_accuracy": 92.0,
    "syntax_validity": 98.0
  },
  "detailed_results": [...]
}
```

## üìà Evaluation Metrics

### 1. Primary Metrics
- **Exact Match**: Perfect string match after normalization
- **Execution Accuracy**: Same query results as gold standard
- **Syntax Validity**: Valid SQL syntax using sqlparse

### 2. Component Analysis
- **SELECT accuracy**: Correct column selection
- **FROM accuracy**: Correct table selection
- **WHERE accuracy**: Correct filtering conditions
- **JOIN accuracy**: Correct table relationships
- **GROUP BY/ORDER BY accuracy**: Correct aggregation/sorting

### 3. Error Analysis
- **Missing keywords**: Required SQL components not generated
- **Extra keywords**: Unnecessary SQL components added
- **Structural differences**: Major query structure changes
- **Length differences**: Token count variations

## üîç System Architecture

### 1. Core Components

#### `VietnameseNL2SQL` Class
- **LLM Integration**: Supports OpenAI and Anthropic models
- **Prompt Engineering**: Optimized for Vietnamese NL2SQL
- **Schema Formatting**: Structures database schema for LLM consumption
- **Response Processing**: Cleans and formats SQL responses

#### `NL2SQLLogger` Class  
- **Request Tracking**: Unique request IDs for all operations
- **LLM Monitoring**: Response times, token usage, model performance
- **SQL Execution**: Database query execution results
- **Error Tracking**: Comprehensive error logging and analysis

#### `NL2SQLEvaluator` Class
- **Multi-metric Evaluation**: Exact match, execution, syntax validation
- **Component Analysis**: Individual SQL clause accuracy
- **Error Categorization**: Detailed error type classification
- **Performance Tracking**: Response times and resource usage

### 2. Prompt Template
The system uses a carefully crafted prompt template:

```
You are an expert in converting Vietnamese natural language questions to SQL queries.

Database Schema:
Tables: {tables}
Columns: {columns} 
Foreign Keys: {foreign_keys}
Primary Keys: {primary_keys}

Important Guidelines:
1. Generate ONLY the SQL query without explanation
2. Use exact table and column names from schema
3. Handle Vietnamese text carefully
4. Use proper SQL syntax and formatting
5. Consider table relationships for JOINs

Vietnamese Question: {question}

SQL Query:
```

## üéØ Best Practices

### 1. Model Selection
- **GPT-4o**: Best accuracy, higher cost
- **GPT-4o-mini**: Good balance of accuracy and cost
- **Claude-3-Haiku**: Fast responses, lower cost
- **Claude-3-Sonnet**: Better reasoning, moderate cost

### 2. Evaluation Strategy
```bash
# Start with small samples for quick testing
python config_nl2sql.py --samples 5

# Increase gradually for comprehensive evaluation  
python config_nl2sql.py --samples 50

# Full evaluation for final results
python config_nl2sql.py --samples -1
```

### 3. Error Analysis
Check logs for common issues:
- Schema mismatches
- Vietnamese character handling
- Complex query structures
- Database connection issues

## üìö Examples

### Example 1: Architecture Database
```
Question: "C√≥ t·∫•t c·∫£ bao nhi√™u ki·∫øn tr√∫c s∆∞ n·ªØ?"
Generated SQL: "SELECT COUNT(*) FROM ki·∫øn_tr√∫c_s∆∞ WHERE gi·ªõi_t√≠nh = 'female'"
Gold SQL: "SELECT COUNT(*) FROM ki·∫øn_tr√∫c_s∆∞ WHERE gi·ªõi_t√≠nh = 'female'"
Result: ‚úÖ Exact Match
```

### Example 2: Academic Database
```
Question: "hi·ªÉn th·ªã trang ch·ªß c·ªßa h·ªôi ngh·ªã PVLDB"
Generated SQL: "SELECT trang_ch·ªß FROM t·∫°p_ch√≠ WHERE t√™n = 'PVLDB'"
Gold SQL: "SELECT trang_ch·ªß FROM t·∫°p_ch√≠ WHERE t√™n = 'PVLDB'"
Result: ‚úÖ Exact Match
```

## üîß Troubleshooting

### Common Issues

#### 1. API Key Errors
```bash
‚ùå Error: No API keys found in environment!
```
**Solution**: Set API keys in `.env` file

#### 2. Dataset Not Found
```bash
‚ùå Dataset not found: dataset/ViText2SQL/syllable-level/dev.json
```
**Solution**: Ensure dataset is properly loaded and paths are correct

#### 3. Database Connection Issues
```bash
‚ùå Database execution error: no such table
```
**Solution**: Check if SQLite databases exist in `sqlite_dbs/` directory

#### 4. Model Not Supported
```bash
‚ùå Unsupported model: custom-model
```
**Solution**: Use supported OpenAI or Anthropic models

### Debug Mode
Enable detailed logging:
```bash
export LOG_LEVEL=DEBUG
python config_nl2sql.py --samples 1
```

## üìä Performance Optimization

### 1. Batch Processing
Process multiple samples efficiently:
```python
# Process in batches to manage API rate limits
for batch in batch_samples(data, batch_size=10):
    results.extend(process_batch(batch))
```

### 2. Caching
Cache schema information to reduce processing time:
```python
# Schema is loaded once per evaluation run
tables = load_tables(dataset_path)  # Cached
```

### 3. Parallel Processing
For large evaluations, consider parallel processing:
```bash
# Split dataset and run multiple processes
python config_nl2sql.py --samples 100 --offset 0 &
python config_nl2sql.py --samples 100 --offset 100 &
```

## üéâ Expected Results

Based on preliminary testing, expected performance ranges:

| Model | Exact Match | Execution Accuracy | Syntax Validity |
|-------|-------------|-------------------|-----------------|
| GPT-4o | 75-85% | 85-95% | 95-99% |
| GPT-4o-mini | 65-75% | 80-90% | 90-95% |
| Claude-3-Sonnet | 70-80% | 82-92% | 92-97% |
| Claude-3-Haiku | 60-70% | 75-85% | 88-93% |

*Results may vary based on query complexity and database schema.*

## üöÄ Next Steps

1. **Evaluate Multiple Models**: Compare performance across different LLMs
2. **Analyze Results**: Study error patterns and improvement opportunities  
3. **Optimize Prompts**: Refine prompt engineering for better accuracy
4. **Implement Few-shot**: Add few-shot examples for improved performance
5. **Schema Linking**: Implement advanced schema linking techniques 