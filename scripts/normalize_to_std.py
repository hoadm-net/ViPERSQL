#!/usr/bin/env python3
"""
Script chu·∫©n h√≥a ViText2SQL dataset cho h·ªá th·ªëng ƒë√°nh gi√° ViPERSQL
"""

import json
import os
import re
from pathlib import Path
from typing import Dict, List, Any

class DatasetNormalizer:
    def __init__(self, base_path: str = "dataset/ViText2SQL"):
        self.base_path = Path(base_path)
        self.std_path = self.base_path / "std-level"
        self.std_path.mkdir(exist_ok=True)
        print(f"üìÅ Chu·∫©n h√≥a d·ªØ li·ªáu ViText2SQL cho ViPERSQL")
        print(f"üìÇ Th∆∞ m·ª•c g·ªëc: {self.base_path}")
        print(f"üìÇ Th∆∞ m·ª•c ƒë√≠ch: {self.std_path}")
    
    def normalize_sql_query(self, sql: str) -> str:
        """Chu·∫©n h√≥a c√¢u truy v·∫•n SQL"""
        # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng d∆∞ th·ª´a
        sql = re.sub(r'\s+', ' ', sql.strip())
        
        # Chu·∫©n h√≥a alias format
        sql = re.sub(r'FROM\s+(\w+)\s+AS\s+(\w+)', r'FROM \1 AS \2', sql)
        
        # Lo·∫°i b·ªè d·∫•u ch·∫•m ph·∫©y cu·ªëi
        sql = sql.rstrip(';')
        
        return sql
    
    def normalize_dataset(self, input_file: str, output_file: str):
        """Chu·∫©n h√≥a dataset file"""
        print(f"Chu·∫©n h√≥a {input_file} -> {output_file}")
        
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        normalized_data = []
        for item in data:
            normalized_item = {
                "question": item["question"].strip(),
                "query": self.normalize_sql_query(item["query"]),
                "db_id": item["db_id"],
                "question_id": item["question_id"]
            }
            normalized_data.append(normalized_item)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(normalized_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ ƒê√£ chu·∫©n h√≥a {len(normalized_data)} m·∫´u")
    
    def normalize_schema(self, input_file: str, output_file: str):
        """Chu·∫©n h√≥a database schema"""
        print(f"Chu·∫©n h√≥a schema {input_file} -> {output_file}")
        
        with open(input_file, 'r', encoding='utf-8') as f:
            schema = json.load(f)
        
        # Chu·∫©n h√≥a t√™n b·∫£ng v√† c·ªôt
        for table in schema["tables"]:
            table["table_name"] = table["table_name"].strip()
            for column in table["columns"]:
                column["name"] = column["name"].strip()
                column["type"] = column["type"].upper()
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(schema, f, ensure_ascii=False, indent=2)
        
        print("‚úÖ ƒê√£ chu·∫©n h√≥a schema")
    
    def create_gold_sql(self, data_file: str, output_file: str):
        """T·∫°o file gold SQL cho test set"""
        print(f"T·∫°o gold SQL {data_file} -> {output_file}")
        
        with open(data_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        gold_sql = []
        for item in data:
            sql_line = f"-- {item['question_id']}\n{item['query']};"
            gold_sql.append(sql_line)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n\n'.join(gold_sql))
        
        print(f"‚úÖ ƒê√£ t·∫°o gold SQL cho {len(gold_sql)} m·∫´u")
    
    def process_all(self):
        """X·ª≠ l√Ω to√†n b·ªô dataset"""
        print("üöÄ B·∫Øt ƒë·∫ßu chu·∫©n h√≥a ViText2SQL dataset...")
        
        # S·ª≠ d·ª•ng word-level l√†m ngu·ªìn d·ªØ li·ªáu g·ªëc
        source_path = self.base_path / "word-level"
        
        # Chu·∫©n h√≥a c√°c file dataset
        for split in ["train", "dev", "test"]:
            input_file = source_path / f"{split}.json"
            output_file = self.std_path / f"{split}.json"
            
            if input_file.exists():
                self.normalize_dataset(str(input_file), str(output_file))
        
        # Chu·∫©n h√≥a schema
        schema_input = source_path / "tables.json"
        schema_output = self.std_path / "tables.json"
        
        if schema_input.exists():
            self.normalize_schema(str(schema_input), str(schema_output))
        
        # T·∫°o gold SQL cho test set
        test_file = self.std_path / "test.json"
        gold_sql_file = self.std_path / "test_gold.sql"
        
        if test_file.exists():
            self.create_gold_sql(str(test_file), str(gold_sql_file))
        
        print("üéâ Ho√†n th√†nh chu·∫©n h√≥a dataset!")

def main():
    normalizer = DatasetNormalizer()
    normalizer.process_all()

if __name__ == "__main__":
    main() 